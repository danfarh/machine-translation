{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rp0K3niKxPZU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import numpy as np\n",
        "import codecs\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ts9J6fvnugp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9vwr46eByCod"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue9B-p-YtspM"
      },
      "source": [
        "# **Read Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 101S8yZESRK5YL0a886tTz1hnCFzhaRxe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD8pKoE76EOC",
        "outputId": "10375cf7-46bb-4615-ac36-dff48c42b9ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=101S8yZESRK5YL0a886tTz1hnCFzhaRxe\n",
            "To: /content/en-fa_MT_dataset.csv\n",
            "100% 55.4M/55.4M [00:01<00:00, 50.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ny2F7S1dtX5t"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('en-fa_MT_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FSAMHB6u6vXQ",
        "outputId": "c0612f11-bcbf-44da-c406-3490b5b8ce98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     en                    fa\n",
              "0     raspy breathing .          صداي خر خر .\n",
              "1                 dad .                 پدر .\n",
              "2  maybe its the wind .  شايد صداي باد باشه ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c2a9c20-8d68-4c3a-b3c6-05c0116b2c67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>raspy breathing .</td>\n",
              "      <td>صداي خر خر .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dad .</td>\n",
              "      <td>پدر .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maybe its the wind .</td>\n",
              "      <td>شايد صداي باد باشه .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c2a9c20-8d68-4c3a-b3c6-05c0116b2c67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c2a9c20-8d68-4c3a-b3c6-05c0116b2c67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c2a9c20-8d68-4c3a-b3c6-05c0116b2c67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6b4nVw9V27v",
        "outputId": "c0b6bbf8-91c4-4bef-ef60-499667bb0be9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "612086"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VrUBKueG8qsO"
      },
      "outputs": [],
      "source": [
        "data['en_size'] = data['en'].str.count(' ')\n",
        "data['fa_size'] = data['fa'].str.count(' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "peSpf3B0J0gE",
        "outputId": "e231e69d-34a2-41e3-95f4-db04a154762f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     en                                         fa  en_size  \\\n",
              "0     raspy breathing .                               صداي خر خر .        2   \n",
              "1                 dad .                                      پدر .        1   \n",
              "2  maybe its the wind .                       شايد صداي باد باشه .        4   \n",
              "3                  no .                                       نه .        1   \n",
              "4    stop please stop .  دست نگه داريد خواهش ميکنم دست نگه داريد .        3   \n",
              "\n",
              "   fa_size  \n",
              "0        3  \n",
              "1        1  \n",
              "2        4  \n",
              "3        1  \n",
              "4        8  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6583e5d3-574b-46ab-92b6-3c79b71f2bfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "      <th>en_size</th>\n",
              "      <th>fa_size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>raspy breathing .</td>\n",
              "      <td>صداي خر خر .</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dad .</td>\n",
              "      <td>پدر .</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maybe its the wind .</td>\n",
              "      <td>شايد صداي باد باشه .</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no .</td>\n",
              "      <td>نه .</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stop please stop .</td>\n",
              "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد .</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6583e5d3-574b-46ab-92b6-3c79b71f2bfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6583e5d3-574b-46ab-92b6-3c79b71f2bfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6583e5d3-574b-46ab-92b6-3c79b71f2bfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "chvRi3LHNQ4r"
      },
      "outputs": [],
      "source": [
        "data['en_no_punctuation'] = data['en'].str.replace('[^\\w\\s]','')\n",
        "data['en_no_punctuation'] = '<start> ' + data[\"en_no_punctuation\"].str.lower() + ' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Pkso4iAQQBC7"
      },
      "outputs": [],
      "source": [
        "data['fa_no_punctuation'] = '<start> ' + data['fa'].str.replace('[^\\w\\s]','') + ' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5nW4l4i2QF48",
        "outputId": "9a73892b-aabe-498f-eb20-2fd5b53f6afd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     en                                         fa  en_size  \\\n",
              "0     raspy breathing .                               صداي خر خر .        2   \n",
              "1                 dad .                                      پدر .        1   \n",
              "2  maybe its the wind .                       شايد صداي باد باشه .        4   \n",
              "3                  no .                                       نه .        1   \n",
              "4    stop please stop .  دست نگه داريد خواهش ميکنم دست نگه داريد .        3   \n",
              "\n",
              "   fa_size                  en_no_punctuation  \\\n",
              "0        3     <start> raspy breathing  <end>   \n",
              "1        1                 <start> dad  <end>   \n",
              "2        4  <start> maybe its the wind  <end>   \n",
              "3        1                  <start> no  <end>   \n",
              "4        8    <start> stop please stop  <end>   \n",
              "\n",
              "                                   fa_no_punctuation  \n",
              "0                          <start> صداي خر خر  <end>  \n",
              "1                                 <start> پدر  <end>  \n",
              "2                  <start> شايد صداي باد باشه  <end>  \n",
              "3                                  <start> نه  <end>  \n",
              "4  <start> دست نگه داريد خواهش ميکنم دست نگه داري...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acda3043-b21f-4ecd-a7cd-1535fe2e128a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fa</th>\n",
              "      <th>en_size</th>\n",
              "      <th>fa_size</th>\n",
              "      <th>en_no_punctuation</th>\n",
              "      <th>fa_no_punctuation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>raspy breathing .</td>\n",
              "      <td>صداي خر خر .</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;start&gt; raspy breathing  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; صداي خر خر  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dad .</td>\n",
              "      <td>پدر .</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; dad  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; پدر  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maybe its the wind .</td>\n",
              "      <td>شايد صداي باد باشه .</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>&lt;start&gt; maybe its the wind  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; شايد صداي باد باشه  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no .</td>\n",
              "      <td>نه .</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;start&gt; no  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; نه  &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>stop please stop .</td>\n",
              "      <td>دست نگه داريد خواهش ميکنم دست نگه داريد .</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>&lt;start&gt; stop please stop  &lt;end&gt;</td>\n",
              "      <td>&lt;start&gt; دست نگه داريد خواهش ميکنم دست نگه داري...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acda3043-b21f-4ecd-a7cd-1535fe2e128a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acda3043-b21f-4ecd-a7cd-1535fe2e128a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acda3043-b21f-4ecd-a7cd-1535fe2e128a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jp8cPPlxQrPH",
        "outputId": "662a1881-40d9-4755-aa6f-d3c7994b9ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> پدر  <end>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data.loc[1, 'fa_no_punctuation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZEwetVWnyDAN"
      },
      "outputs": [],
      "source": [
        "en_data = data['en_no_punctuation'].values[0:150_000]\n",
        "fa_data = data['fa_no_punctuation'].values[0:150_000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3FH33q5EylSd"
      },
      "outputs": [],
      "source": [
        "en_data = [re.sub('\\s+', ' ', str(sentence)) for sentence in en_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DlwYpjMw1s9p"
      },
      "outputs": [],
      "source": [
        "fa_data = [re.sub('\\s+', ' ', str(sentence)) for sentence in fa_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHW84ZDF2VdP",
        "outputId": "e2f87b90-5ed0-4d20-d067-099d8d85caa3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> raspy breathing <end>',\n",
              " '<start> dad <end>',\n",
              " '<start> maybe its the wind <end>',\n",
              " '<start> no <end>',\n",
              " '<start> stop please stop <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "en_data[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmQP3VSR0CFg",
        "outputId": "18ef4ed5-c2f8-4d21-bd13-7aa180c58fcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> صداي خر خر <end>',\n",
              " '<start> پدر <end>',\n",
              " '<start> شايد صداي باد باشه <end>',\n",
              " '<start> نه <end>',\n",
              " '<start> دست نگه داريد خواهش ميکنم دست نگه داريد <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "fa_data[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ],
      "metadata": {
        "id": "PTpoxVRulUOr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = Tokenizer()\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer"
      ],
      "metadata": {
        "id": "PZIhEDoKmXeL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    inp_lang = en_data\n",
        "    targ_lang = fa_data\n",
        "    input_tensor, input_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, target_lang_tokenizer = tokenize(targ_lang)\n",
        "    return input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer"
      ],
      "metadata": {
        "id": "7LaL41zUmcPi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer = load_dataset()"
      ],
      "metadata": {
        "id": "KqgSoCPtmg2X"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uClexdnzpYu8",
        "outputId": "48f147a1-5d4f-4ca2-ecfa-13c1976e79a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    2, 17589,  1808, ...,     0,     0,     0],\n",
              "       [    2,   325,     1, ...,     0,     0,     0],\n",
              "       [    2,   173,    30, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    2,   272,    23, ...,     0,     0,     0],\n",
              "       [    2,   272,    23, ...,     0,     0,     0],\n",
              "       [    2,    90,    19, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_tensor.shape)\n",
        "print(target_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oacYnq4dTHLT",
        "outputId": "40673fa3-5efb-45a4-e868-3eae71dcd9b0"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150000, 36)\n",
            "(150000, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "metadata": {
        "id": "BzV6jFj4pdIy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length_targ, max_length_inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPhTFFzb0y-A",
        "outputId": "0989e4e5-e3cf-4b10-9b8d-6bdd269a5468"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "metadata": {
        "id": "_NNXzk--02WM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tensor_to_word(lang_tokenizer, tensor):\n",
        "    for t in tensor:\n",
        "        if t != 0:\n",
        "            print(t, ': ', lang_tokenizer.index_word[t])"
      ],
      "metadata": {
        "id": "JMb5RACK06DH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_tensor_to_word(input_lang_tokenizer, input_tensor[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eWEApLL1D54",
        "outputId": "a0761466-b801-441f-e73c-b10fe1501442"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 :  start\n",
            "17589 :  raspy\n",
            "1808 :  breathing\n",
            "1 :  end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFXGUKI01FfI",
        "outputId": "130f7613-df18-4e54-eb1f-e0a4859e6b36"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    2, 17589,  1808,     1,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX7dQR2SRdEs",
        "outputId": "2db2410f-4cc7-4ba8-d505-da42a89977e1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150000, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(target_lang_tokenizer.word_index)[0:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ya5bD2El1XMH",
        "outputId": "c6a710ad-c39d-4f8f-d58f-a1faab32cdca"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['start',\n",
              " 'end',\n",
              " 'را',\n",
              " 'من',\n",
              " 'به',\n",
              " 'تو',\n",
              " 'و',\n",
              " 'که',\n",
              " 'از',\n",
              " 'اين',\n",
              " 'اون',\n",
              " 'يک',\n",
              " 'ما',\n",
              " 'در',\n",
              " 'با',\n",
              " 'كه',\n",
              " 'نه',\n",
              " 'هم',\n",
              " 'براي',\n",
              " 'بود']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 1024\n",
        "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(input_lang_tokenizer.word_index) + 1\n",
        "vocab_targ_size = len(target_lang_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "ltC2JinL1gV9"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "metadata": {
        "id": "LomxF-KhFGYu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "    def initilize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "metadata": {
        "id": "opTUYsZLFH99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "UYYiiUB1FJ-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6w6-2lnHFY8i",
        "outputId": "61b1d4a7-31a0-4916-e87d-d8ce6c83e8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Encoder at 0x7f309411c0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_hidden = encoder.initilize_hidden_state()\n",
        "simple_hidden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyMWeRyYFakl",
        "outputId": "702fa6ab-13a0-4c00-b79c-9a3ecb02a3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))"
      ],
      "metadata": {
        "id": "chDVJc0VFcEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder(example_input_batch, simple_hidden)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMtqHSWiFeLv",
        "outputId": "ca38a76f-83a5-40f6-98b5-63ceb4307da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 36, 1024), dtype=float32, numpy=\n",
              " array([[[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [ 4.69231186e-03, -2.65270146e-03, -4.60728770e-03, ...,\n",
              "          -7.93961156e-03,  3.41843884e-03, -5.37993945e-03],\n",
              "         [-1.30449748e-03, -6.89162826e-03,  1.69798988e-03, ...,\n",
              "           1.20301777e-03, -2.15936359e-03, -5.85939642e-03],\n",
              "         ...,\n",
              "         [-5.66742732e-04, -1.73659122e-03,  1.18973833e-02, ...,\n",
              "          -3.74847581e-03, -8.98322184e-03,  1.18433516e-02],\n",
              "         [-5.66839240e-04, -1.73657713e-03,  1.18971877e-02, ...,\n",
              "          -3.74859222e-03, -8.98294710e-03,  1.18434522e-02],\n",
              "         [-5.66906878e-04, -1.73656992e-03,  1.18970610e-02, ...,\n",
              "          -3.74865602e-03, -8.98277201e-03,  1.18434951e-02]],\n",
              " \n",
              "        [[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [-5.16955974e-04,  3.83880106e-03, -1.97829120e-03, ...,\n",
              "          -4.31128126e-03, -6.97018206e-03, -4.10797680e-03],\n",
              "         [ 2.47546169e-03,  7.30671105e-04, -1.03670340e-02, ...,\n",
              "          -5.58143435e-03, -5.81217743e-03,  1.97405042e-03],\n",
              "         ...,\n",
              "         [-5.66886214e-04, -1.73674291e-03,  1.18981395e-02, ...,\n",
              "          -3.74886836e-03, -8.98378156e-03,  1.18431244e-02],\n",
              "         [-5.66907518e-04, -1.73670356e-03,  1.18976850e-02, ...,\n",
              "          -3.74883972e-03, -8.98330286e-03,  1.18433405e-02],\n",
              "         [-5.66937029e-04, -1.73666887e-03,  1.18973888e-02, ...,\n",
              "          -3.74881178e-03, -8.98299553e-03,  1.18434448e-02]],\n",
              " \n",
              "        [[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [ 9.56487143e-04,  8.75006896e-03, -5.70350559e-03, ...,\n",
              "          -4.34485264e-03, -1.60090986e-03, -9.55186132e-03],\n",
              "         [-3.23050306e-03,  2.55464530e-03, -2.37175100e-03, ...,\n",
              "           5.39674936e-03, -3.41714825e-03, -3.71426297e-03],\n",
              "         ...,\n",
              "         [-5.67001989e-04, -1.73654198e-03,  1.18968850e-02, ...,\n",
              "          -3.74871818e-03, -8.98256339e-03,  1.18434932e-02],\n",
              "         [-5.67015377e-04, -1.73654966e-03,  1.18968636e-02, ...,\n",
              "          -3.74871632e-03, -8.98252986e-03,  1.18434876e-02],\n",
              "         [-5.67023875e-04, -1.73655688e-03,  1.18968496e-02, ...,\n",
              "          -3.74871399e-03, -8.98250937e-03,  1.18434830e-02]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [ 1.17206862e-02,  8.48614029e-04,  4.12659300e-03, ...,\n",
              "          -1.11760264e-02, -3.28622200e-03, -2.47183209e-03],\n",
              "         [ 1.06530394e-02, -1.08124537e-03,  2.29035341e-03, ...,\n",
              "          -6.32834015e-03,  3.44667863e-03, -1.51547906e-03],\n",
              "         ...,\n",
              "         [-5.66937553e-04, -1.73650985e-03,  1.18970424e-02, ...,\n",
              "          -3.74870747e-03, -8.98270775e-03,  1.18435100e-02],\n",
              "         [-5.66975446e-04, -1.73653127e-03,  1.18969651e-02, ...,\n",
              "          -3.74871958e-03, -8.98261834e-03,  1.18435156e-02],\n",
              "         [-5.67000243e-04, -1.73654396e-03,  1.18969148e-02, ...,\n",
              "          -3.74872284e-03, -8.98256246e-03,  1.18435081e-02]],\n",
              " \n",
              "        [[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [ 1.02202576e-02,  3.67201120e-03,  5.69859007e-03, ...,\n",
              "          -4.76275804e-03, -1.72179821e-03, -2.97312438e-03],\n",
              "         [ 1.54173858e-02,  3.32183577e-03,  4.95759677e-03, ...,\n",
              "          -9.55509581e-03, -3.77411395e-03,  2.60614138e-03],\n",
              "         ...,\n",
              "         [-5.66990988e-04, -1.73655793e-03,  1.18968897e-02, ...,\n",
              "          -3.74873774e-03, -8.98257084e-03,  1.18435044e-02],\n",
              "         [-5.67008741e-04, -1.73656188e-03,  1.18968664e-02, ...,\n",
              "          -3.74873122e-03, -8.98253359e-03,  1.18434932e-02],\n",
              "         [-5.67020266e-04, -1.73656247e-03,  1.18968524e-02, ...,\n",
              "          -3.74872447e-03, -8.98250937e-03,  1.18434858e-02]],\n",
              " \n",
              "        [[ 4.76778811e-03,  4.27769228e-05,  6.47662440e-04, ...,\n",
              "          -9.46064387e-03, -2.78141652e-03, -1.52624901e-02],\n",
              "         [ 1.01224543e-03, -6.20387169e-03,  1.24845793e-02, ...,\n",
              "          -8.87017231e-03, -9.10037546e-04, -1.55817969e-02],\n",
              "         [ 1.39868265e-04, -2.84725800e-03,  5.43980161e-03, ...,\n",
              "           2.90615205e-03, -2.62532756e-03, -2.35157050e-02],\n",
              "         ...,\n",
              "         [-5.66956995e-04, -1.73653918e-03,  1.18970517e-02, ...,\n",
              "          -3.74881132e-03, -8.98273475e-03,  1.18435193e-02],\n",
              "         [-5.66985516e-04, -1.73655106e-03,  1.18969772e-02, ...,\n",
              "          -3.74878244e-03, -8.98263976e-03,  1.18435193e-02],\n",
              "         [-5.67005482e-04, -1.73655746e-03,  1.18969250e-02, ...,\n",
              "          -3.74876126e-03, -8.98257922e-03,  1.18435100e-02]]],\n",
              "       dtype=float32)>, <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[-0.00056691, -0.00173657,  0.01189706, ..., -0.00374866,\n",
              "         -0.00898277,  0.0118435 ],\n",
              "        [-0.00056694, -0.00173667,  0.01189739, ..., -0.00374881,\n",
              "         -0.008983  ,  0.01184344],\n",
              "        [-0.00056702, -0.00173656,  0.01189685, ..., -0.00374871,\n",
              "         -0.00898251,  0.01184348],\n",
              "        ...,\n",
              "        [-0.000567  , -0.00173654,  0.01189691, ..., -0.00374872,\n",
              "         -0.00898256,  0.01184351],\n",
              "        [-0.00056702, -0.00173656,  0.01189685, ..., -0.00374872,\n",
              "         -0.00898251,  0.01184349],\n",
              "        [-0.00056701, -0.00173656,  0.01189693, ..., -0.00374876,\n",
              "         -0.00898258,  0.01184351]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_output, simple_states = encoder(example_input_batch, simple_hidden)"
      ],
      "metadata": {
        "id": "4qmwnBSCFikY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(keras.layers.Layer):\n",
        "    def __init__ (self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "    def call (self, query, values):\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "        atteion_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = atteion_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, atteion_weights"
      ],
      "metadata": {
        "id": "q8Tbjc9OFlyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = Attention(10)\n",
        "attention_layer(simple_hidden, simple_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcuDTyI7FoP7",
        "outputId": "d793c04f-2b6d-439c-8340-d762b90e74e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[-0.00144463, -0.00295026,  0.00912169, ..., -0.0033915 ,\n",
              "         -0.00630622,  0.00736675],\n",
              "        [ 0.0004775 ,  0.00076909,  0.00818022, ..., -0.00259093,\n",
              "         -0.00583887,  0.00577949],\n",
              "        [ 0.00047016, -0.00100788,  0.00978865, ..., -0.00231028,\n",
              "         -0.00753438,  0.0081187 ],\n",
              "        ...,\n",
              "        [ 0.00062883, -0.0015618 ,  0.00886149, ..., -0.00193209,\n",
              "         -0.00646909,  0.0079165 ],\n",
              "        [ 0.00136512, -0.00261301,  0.01090115, ..., -0.0030711 ,\n",
              "         -0.00766282,  0.00884432],\n",
              "        [-0.0011033 , -0.00249512,  0.01094301, ..., -0.00198215,\n",
              "         -0.0074179 ,  0.00666509]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 36, 1), dtype=float32, numpy=\n",
              " array([[[0.02783762],\n",
              "         [0.02813881],\n",
              "         [0.02766192],\n",
              "         ...,\n",
              "         [0.02767112],\n",
              "         [0.02767109],\n",
              "         [0.02767108]],\n",
              " \n",
              "        [[0.0278667 ],\n",
              "         [0.02756146],\n",
              "         [0.02817884],\n",
              "         ...,\n",
              "         [0.02770007],\n",
              "         [0.02770003],\n",
              "         [0.02770001]],\n",
              " \n",
              "        [[0.02782317],\n",
              "         [0.02852913],\n",
              "         [0.02842096],\n",
              "         ...,\n",
              "         [0.02765671],\n",
              "         [0.02765671],\n",
              "         [0.02765671]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.02785218],\n",
              "         [0.02793468],\n",
              "         [0.02842661],\n",
              "         ...,\n",
              "         [0.02768556],\n",
              "         [0.02768555],\n",
              "         [0.02768555]],\n",
              " \n",
              "        [[0.02786022],\n",
              "         [0.02787188],\n",
              "         [0.02795978],\n",
              "         ...,\n",
              "         [0.02769354],\n",
              "         [0.02769353],\n",
              "         [0.02769353]],\n",
              " \n",
              "        [[0.02784104],\n",
              "         [0.02788873],\n",
              "         [0.02822595],\n",
              "         ...,\n",
              "         [0.02767449],\n",
              "         [0.02767448],\n",
              "         [0.02767448]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_result, attention_weights = attention_layer(simple_hidden, simple_output)"
      ],
      "metadata": {
        "id": "GXIak5pXFqiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.Model):\n",
        "    def __init__ (self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True)\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        self.attention = Attention(self.dec_units)\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights"
      ],
      "metadata": {
        "id": "e0mzVvDoFt30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(vocab_targ_size, embedding_dim, units, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "fIKqXfk2Fwbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder(tf.random.uniform((BATCH_SIZE, 1)), simple_hidden, simple_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oxZpNF5FyT4",
        "outputId": "eeca214f-fd11-43c7-aef0-b34d62cf2bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 14063), dtype=float32, numpy=\n",
              " array([[-0.0018821 , -0.00126402,  0.00187614, ...,  0.001965  ,\n",
              "         -0.00266947, -0.00211682],\n",
              "        [-0.00188992, -0.00151722,  0.00239011, ...,  0.00195522,\n",
              "         -0.00265795, -0.00207566],\n",
              "        [-0.00188682, -0.00117242,  0.00215933, ...,  0.00189119,\n",
              "         -0.00303163, -0.00205385],\n",
              "        ...,\n",
              "        [-0.0018289 , -0.00126717,  0.00188937, ...,  0.0020097 ,\n",
              "         -0.00264076, -0.00219136],\n",
              "        [-0.00179501, -0.00110777,  0.00216814, ...,  0.00179939,\n",
              "         -0.00272797, -0.0020465 ],\n",
              "        [-0.00163617, -0.00099326,  0.0019545 , ...,  0.00171457,\n",
              "         -0.0026966 , -0.00203061]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
              " array([[ 0.00957308, -0.00541056, -0.00229575, ..., -0.00043806,\n",
              "         -0.00710973,  0.00463084],\n",
              "        [ 0.00906679, -0.00590708, -0.00245306, ..., -0.00011788,\n",
              "         -0.00704469,  0.0044682 ],\n",
              "        [ 0.00920943, -0.00516213, -0.00242189, ..., -0.00047858,\n",
              "         -0.00716483,  0.0038986 ],\n",
              "        ...,\n",
              "        [ 0.00885256, -0.00529325, -0.00250528, ..., -0.00076962,\n",
              "         -0.00751016,  0.00397095],\n",
              "        [ 0.00890241, -0.0049567 , -0.00236681, ..., -0.00064125,\n",
              "         -0.00714773,  0.00448597],\n",
              "        [ 0.00846605, -0.00529896, -0.00209163, ..., -0.00085254,\n",
              "         -0.00688239,  0.00565565]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(64, 36, 1), dtype=float32, numpy=\n",
              " array([[[0.02791023],\n",
              "         [0.02810971],\n",
              "         [0.02839305],\n",
              "         ...,\n",
              "         [0.02773006],\n",
              "         [0.02773005],\n",
              "         [0.02773005]],\n",
              " \n",
              "        [[0.02785259],\n",
              "         [0.02800395],\n",
              "         [0.02764906],\n",
              "         ...,\n",
              "         [0.02767279],\n",
              "         [0.02767279],\n",
              "         [0.02767279]],\n",
              " \n",
              "        [[0.02793483],\n",
              "         [0.02822844],\n",
              "         [0.02803042],\n",
              "         ...,\n",
              "         [0.02775449],\n",
              "         [0.02775449],\n",
              "         [0.02775449]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.02792507],\n",
              "         [0.02788912],\n",
              "         [0.02795819],\n",
              "         ...,\n",
              "         [0.0277448 ],\n",
              "         [0.0277448 ],\n",
              "         [0.0277448 ]],\n",
              " \n",
              "        [[0.02792412],\n",
              "         [0.02787695],\n",
              "         [0.02786777],\n",
              "         ...,\n",
              "         [0.02774385],\n",
              "         [0.02774385],\n",
              "         [0.02774385]],\n",
              " \n",
              "        [[0.02788456],\n",
              "         [0.02817985],\n",
              "         [0.0283649 ],\n",
              "         ...,\n",
              "         [0.02770455],\n",
              "         [0.02770455],\n",
              "         [0.02770455]]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "Yn81oMLA3zwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "N1m5PH2TI_Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = 'chckpnts'\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "metadata": {
        "id": "1Se7GkxZI6zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        dec_input = tf.expand_dims([target_lang_tokenizer.word_index['start']] * BATCH_SIZE, 1)\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "DxqJMGDsI6nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 10\n",
        "for epoch in range(EPOCH):\n",
        "    enc_hidden = encoder.initilize_hidden_state()\n",
        "    total_loss = 0\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "        print('Epoch: ', epoch)\n",
        "        print('Loss: ', batch_loss.numpy())\n",
        "    checkpoint.save(file_prefix='test1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "m3itFUujI6Vd",
        "outputId": "dd2d61e1-52a3-48b5-f583-b43cfe160617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n",
            "Loss:  2.2077267\n",
            "Epoch:  0\n",
            "Loss:  2.332972\n",
            "Epoch:  0\n",
            "Loss:  2.2280352\n",
            "Epoch:  0\n",
            "Loss:  1.8233036\n",
            "Epoch:  0\n",
            "Loss:  1.6429102\n",
            "Epoch:  0\n",
            "Loss:  1.5432467\n",
            "Epoch:  0\n",
            "Loss:  1.6914159\n",
            "Epoch:  0\n",
            "Loss:  1.6284164\n",
            "Epoch:  0\n",
            "Loss:  1.7932659\n",
            "Epoch:  0\n",
            "Loss:  1.9295249\n",
            "Epoch:  0\n",
            "Loss:  1.8394992\n",
            "Epoch:  0\n",
            "Loss:  1.79862\n",
            "Epoch:  0\n",
            "Loss:  1.8266114\n",
            "Epoch:  0\n",
            "Loss:  1.8102815\n",
            "Epoch:  0\n",
            "Loss:  1.8831841\n",
            "Epoch:  0\n",
            "Loss:  1.6486939\n",
            "Epoch:  0\n",
            "Loss:  1.961117\n",
            "Epoch:  0\n",
            "Loss:  1.6935047\n",
            "Epoch:  0\n",
            "Loss:  1.7654332\n",
            "Epoch:  0\n",
            "Loss:  1.5875679\n",
            "Epoch:  0\n",
            "Loss:  1.7287428\n",
            "Epoch:  0\n",
            "Loss:  1.7666519\n",
            "Epoch:  0\n",
            "Loss:  1.6757268\n",
            "Epoch:  0\n",
            "Loss:  1.8113145\n",
            "Epoch:  0\n",
            "Loss:  1.5425848\n",
            "Epoch:  0\n",
            "Loss:  1.6027446\n",
            "Epoch:  0\n",
            "Loss:  1.616174\n",
            "Epoch:  0\n",
            "Loss:  1.7288326\n",
            "Epoch:  0\n",
            "Loss:  1.5646371\n",
            "Epoch:  0\n",
            "Loss:  1.6300225\n",
            "Epoch:  0\n",
            "Loss:  1.6634853\n",
            "Epoch:  0\n",
            "Loss:  1.7320808\n",
            "Epoch:  0\n",
            "Loss:  1.7001557\n",
            "Epoch:  0\n",
            "Loss:  1.5792702\n",
            "Epoch:  0\n",
            "Loss:  1.7471089\n",
            "Epoch:  0\n",
            "Loss:  1.8210549\n",
            "Epoch:  0\n",
            "Loss:  1.5323147\n",
            "Epoch:  0\n",
            "Loss:  1.7209558\n",
            "Epoch:  0\n",
            "Loss:  1.7189449\n",
            "Epoch:  0\n",
            "Loss:  1.7055043\n",
            "Epoch:  0\n",
            "Loss:  1.764668\n",
            "Epoch:  0\n",
            "Loss:  1.7550613\n",
            "Epoch:  0\n",
            "Loss:  1.599401\n",
            "Epoch:  0\n",
            "Loss:  1.641801\n",
            "Epoch:  0\n",
            "Loss:  1.6003243\n",
            "Epoch:  0\n",
            "Loss:  1.6505312\n",
            "Epoch:  0\n",
            "Loss:  1.6834931\n",
            "Epoch:  0\n",
            "Loss:  1.6809901\n",
            "Epoch:  0\n",
            "Loss:  1.5399579\n",
            "Epoch:  0\n",
            "Loss:  1.6156553\n",
            "Epoch:  0\n",
            "Loss:  1.5178647\n",
            "Epoch:  0\n",
            "Loss:  1.5735847\n",
            "Epoch:  0\n",
            "Loss:  1.7401093\n",
            "Epoch:  0\n",
            "Loss:  1.6539054\n",
            "Epoch:  0\n",
            "Loss:  1.799517\n",
            "Epoch:  0\n",
            "Loss:  1.418201\n",
            "Epoch:  0\n",
            "Loss:  1.622228\n",
            "Epoch:  0\n",
            "Loss:  1.4959657\n",
            "Epoch:  0\n",
            "Loss:  1.6030436\n",
            "Epoch:  0\n",
            "Loss:  1.7103055\n",
            "Epoch:  0\n",
            "Loss:  1.5707371\n",
            "Epoch:  0\n",
            "Loss:  1.7021227\n",
            "Epoch:  0\n",
            "Loss:  1.7726012\n",
            "Epoch:  0\n",
            "Loss:  1.7620528\n",
            "Epoch:  0\n",
            "Loss:  1.7755388\n",
            "Epoch:  0\n",
            "Loss:  1.5229503\n",
            "Epoch:  0\n",
            "Loss:  1.8248259\n",
            "Epoch:  0\n",
            "Loss:  1.759539\n",
            "Epoch:  0\n",
            "Loss:  1.5440624\n",
            "Epoch:  0\n",
            "Loss:  1.5985694\n",
            "Epoch:  0\n",
            "Loss:  1.625498\n",
            "Epoch:  0\n",
            "Loss:  1.6677158\n",
            "Epoch:  0\n",
            "Loss:  1.6700821\n",
            "Epoch:  0\n",
            "Loss:  1.7213905\n",
            "Epoch:  0\n",
            "Loss:  1.6516494\n",
            "Epoch:  0\n",
            "Loss:  1.7279981\n",
            "Epoch:  0\n",
            "Loss:  1.6168401\n",
            "Epoch:  0\n",
            "Loss:  1.5023237\n",
            "Epoch:  0\n",
            "Loss:  1.5476679\n",
            "Epoch:  0\n",
            "Loss:  1.5614667\n",
            "Epoch:  0\n",
            "Loss:  1.4485015\n",
            "Epoch:  0\n",
            "Loss:  1.647482\n",
            "Epoch:  0\n",
            "Loss:  1.6481458\n",
            "Epoch:  0\n",
            "Loss:  1.6193758\n",
            "Epoch:  0\n",
            "Loss:  1.6491725\n",
            "Epoch:  0\n",
            "Loss:  1.556177\n",
            "Epoch:  0\n",
            "Loss:  1.5285792\n",
            "Epoch:  0\n",
            "Loss:  1.6448823\n",
            "Epoch:  0\n",
            "Loss:  1.5313208\n",
            "Epoch:  0\n",
            "Loss:  1.7431675\n",
            "Epoch:  0\n",
            "Loss:  1.5875484\n",
            "Epoch:  0\n",
            "Loss:  1.5685658\n",
            "Epoch:  0\n",
            "Loss:  1.5196005\n",
            "Epoch:  0\n",
            "Loss:  1.5615602\n",
            "Epoch:  0\n",
            "Loss:  1.7126609\n",
            "Epoch:  0\n",
            "Loss:  1.7442373\n",
            "Epoch:  0\n",
            "Loss:  1.708444\n",
            "Epoch:  0\n",
            "Loss:  1.5210382\n",
            "Epoch:  0\n",
            "Loss:  1.516255\n",
            "Epoch:  0\n",
            "Loss:  1.872558\n",
            "Epoch:  0\n",
            "Loss:  1.4898108\n",
            "Epoch:  0\n",
            "Loss:  1.6250219\n",
            "Epoch:  0\n",
            "Loss:  1.5619771\n",
            "Epoch:  0\n",
            "Loss:  1.6791832\n",
            "Epoch:  0\n",
            "Loss:  1.6742957\n",
            "Epoch:  0\n",
            "Loss:  1.6002668\n",
            "Epoch:  0\n",
            "Loss:  1.4595739\n",
            "Epoch:  0\n",
            "Loss:  1.656219\n",
            "Epoch:  0\n",
            "Loss:  1.6930244\n",
            "Epoch:  0\n",
            "Loss:  1.5668379\n",
            "Epoch:  0\n",
            "Loss:  1.5926228\n",
            "Epoch:  0\n",
            "Loss:  1.6651375\n",
            "Epoch:  0\n",
            "Loss:  1.5511202\n",
            "Epoch:  0\n",
            "Loss:  1.6792548\n",
            "Epoch:  0\n",
            "Loss:  1.5427617\n",
            "Epoch:  0\n",
            "Loss:  1.5935546\n",
            "Epoch:  0\n",
            "Loss:  1.5367641\n",
            "Epoch:  0\n",
            "Loss:  1.6340396\n",
            "Epoch:  0\n",
            "Loss:  1.5792673\n",
            "Epoch:  0\n",
            "Loss:  1.5850954\n",
            "Epoch:  0\n",
            "Loss:  1.6306225\n",
            "Epoch:  0\n",
            "Loss:  1.6214863\n",
            "Epoch:  0\n",
            "Loss:  1.6313205\n",
            "Epoch:  0\n",
            "Loss:  1.7006938\n",
            "Epoch:  0\n",
            "Loss:  1.6089308\n",
            "Epoch:  0\n",
            "Loss:  1.5274459\n",
            "Epoch:  0\n",
            "Loss:  1.5147418\n",
            "Epoch:  0\n",
            "Loss:  1.7903564\n",
            "Epoch:  0\n",
            "Loss:  1.7376125\n",
            "Epoch:  0\n",
            "Loss:  1.5083776\n",
            "Epoch:  0\n",
            "Loss:  1.898585\n",
            "Epoch:  0\n",
            "Loss:  1.6011199\n",
            "Epoch:  0\n",
            "Loss:  1.6352241\n",
            "Epoch:  0\n",
            "Loss:  1.5264729\n",
            "Epoch:  0\n",
            "Loss:  1.5405482\n",
            "Epoch:  0\n",
            "Loss:  1.4480519\n",
            "Epoch:  0\n",
            "Loss:  1.4915497\n",
            "Epoch:  0\n",
            "Loss:  1.5671341\n",
            "Epoch:  0\n",
            "Loss:  1.6154745\n",
            "Epoch:  0\n",
            "Loss:  1.5912379\n",
            "Epoch:  0\n",
            "Loss:  1.6145031\n",
            "Epoch:  0\n",
            "Loss:  1.6252072\n",
            "Epoch:  0\n",
            "Loss:  1.5153849\n",
            "Epoch:  0\n",
            "Loss:  1.4796896\n",
            "Epoch:  0\n",
            "Loss:  1.5880288\n",
            "Epoch:  0\n",
            "Loss:  1.4431269\n",
            "Epoch:  0\n",
            "Loss:  1.3183073\n",
            "Epoch:  0\n",
            "Loss:  1.6319913\n",
            "Epoch:  0\n",
            "Loss:  1.5254766\n",
            "Epoch:  0\n",
            "Loss:  1.5614668\n",
            "Epoch:  0\n",
            "Loss:  1.7211434\n",
            "Epoch:  0\n",
            "Loss:  1.4910657\n",
            "Epoch:  0\n",
            "Loss:  1.5344368\n",
            "Epoch:  0\n",
            "Loss:  1.5616564\n",
            "Epoch:  0\n",
            "Loss:  1.6614317\n",
            "Epoch:  0\n",
            "Loss:  1.659239\n",
            "Epoch:  0\n",
            "Loss:  1.5459512\n",
            "Epoch:  0\n",
            "Loss:  1.4633497\n",
            "Epoch:  0\n",
            "Loss:  1.6460937\n",
            "Epoch:  0\n",
            "Loss:  1.7034683\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-5d2eb213e1ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-123-2e12d947575e>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, targ, enc_hidden)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdec_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-58f9b06c3090>\u001b[0m in \u001b[0;36mloss_function\u001b[0;34m(real, pred)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m       return losses_utils.compute_weighted_loss(\n\u001b[1;32m    143\u001b[0m           losses, sample_weight, reduction=self._get_reduction())\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0mag_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mag_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, axis)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m   return backend.sparse_categorical_crossentropy(\n\u001b[0;32m-> 1863\u001b[0;31m       y_true, y_pred, from_logits=from_logits, axis=axis)\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36msparse_categorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m   5204\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5205\u001b[0m     res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 5206\u001b[0;31m         labels=target, logits=output)\n\u001b[0m\u001b[1;32m   5207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5208\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mupdate_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_rank\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m   4424\u001b[0m   \"\"\"\n\u001b[1;32m   4425\u001b[0m   return sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4426\u001b[0;31m       labels=labels, logits=logits, name=name)\n\u001b[0m\u001b[1;32m   4427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m   4337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4338\u001b[0m       cost = _sparse_softmax_cross_entropy_with_rank_2_logits(\n\u001b[0;32m-> 4339\u001b[0;31m           precise_logits, labels, name=name)\n\u001b[0m\u001b[1;32m   4340\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_sparse_softmax_cross_entropy_with_rank_2_logits\u001b[0;34m(logits, labels, name)\u001b[0m\n\u001b[1;32m   4236\u001b[0m     \u001b[0;31m# _CrossEntropyGrad() in nn_grad but not here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4237\u001b[0m     cost, _ = gen_nn_ops.sparse_softmax_cross_entropy_with_logits(\n\u001b[0;32m-> 4238\u001b[0;31m         logits, labels, name=name)\n\u001b[0m\u001b[1;32m   4239\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[0;34m(features, labels, name)\u001b[0m\n\u001b[1;32m  11323\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11324\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m> 11325\u001b[0;31m         _ctx, \"SparseSoftmaxCrossEntropyWithLogits\", name, features, labels)\n\u001b[0m\u001b[1;32m  11326\u001b[0m       \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SparseSoftmaxCrossEntropyWithLogitsOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11327\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_senetence(w):\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.~,]+\", \" \", w)\n",
        "    w = w.rstrip().strip()\n",
        "    w = '<strat> ' + w + ' <end>'\n",
        "    return w"
      ],
      "metadata": {
        "id": "DaENPy8B6dyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "    sentence = preprocess_senetence(sentence)\n",
        "    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "    result = ''\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<strat>']], 0)\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
        "        if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "    return result, sentence"
      ],
      "metadata": {
        "id": "gRWxSwTPGBJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DaE3Jp0GKOK",
        "outputId": "f9291e62-a4fa-4024-f43e-868257fdb305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x7f41321bd090>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('hello.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "bXYiZ2uQGL34",
        "outputId": "2605272b-6075-43c7-e5e6-ff353d6329dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-b66e231b9b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-69-1491ed16fe9c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_senetence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_lang_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocess_senetence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y6H_gdwLGPFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "machine_translation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}